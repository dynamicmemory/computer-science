BASIC DEFINITIONS 

Type 1 error - reject the null hypothesis when the null is true. 
Type 2 error - failiing to reject the null when the Ha is true.

A sample statistic changes each time you try to measure it, but a population
parameter remains fixed.



-=-=--=-=-=-=-==-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=
T DISTRIBUTION - ONE SAMPLE MEANS

central limit theory 

Two conditions
- Independence 
- Nearly normal distribution 

if n < 30 and no clear outliers then we assume nearly normal 
if n > 30 and no particularly extreme outliers, then we assume normality

se = std||s / n**0.5
t = (x_hat - mean) / se

df = n - 1
conf interval = x_hat +/- t_star(df) * se

_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+
PAIRED T TEST

Two sets of observations are paired if each obsevation in one set has a special 
connection with exactly one observation in the other.

Example 
University book store prices - Amazon prices

To analyze a paired set we simply analyze the differences.
X_hat = the average of the differences
n = n
s = std of the differences 
df = n - 1 
EVERYTHING IS THE SAME AS A ONE SAMPLE MEANS TEST 

Ho: mean = 0, There is no difference in the average textbooks price 
Ha: mean != 0, There is a difference in average prices.

point estimate = diff = post treatment - pre treatment
t = (x_hat - 0) / (s / n**0.5)

_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+
DIFFERENCE BETWEEN TWO MEANS 

point estimate = the difference in the two means 
X_exp - X_control 

Check for independence and Normality, same as before 

standard error is difference 

se = ((std_1**2 / n_1) + (std_2**2 / n_2))**0.5 
Break this calc into smaller pieces because i always seem to get it wrong 

df are usually calcd by a computer but by hand you take the smaller or n - 1 
between the two means 

Ho: µ1 = µ2: there is no difference in means between the two thingys 
Ha: µ1 != µ2 or > or <: There is a difference between means.
_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+_
ANOVA

analysis of variance

Means between multiple groups, greater than two groups 

F statistic 

Ho: There is no difference between means u1 = u2 = u3 
Ha: At least one mean is different 

CONDITIONS 

- independence
- Nearly normal data in each group 
- Variability across the groups is about equal i.e the difference between the 
smallest std and the larges is less than 2, small_std * 2 > largest

MSG = variance between the groups 
df = k - 1 with k being the number of groups 
To get the MSG you do 1/df * summed squares 

MSE = Variance between obsevations 
df = n - k with k being the number of groups and n being the number of observations 
To get the MSE you do 1/df * summed squares 

F stat = MSG / MSE 

Plug the f stat in to get the p value and compare with hypothesis's for an answer

If p value is less than 0.05, you can use a two sample t test to find out which 
group there is a difference in. There is also the bonferroni correction using 
software. Which ever comparison of groups is less than 0.05, is where you find 
the difference in groups 

There is no conf interval for anova 

_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+
LINEAR REGRESSION 

When determining a relationship you address three aspects

- Linear or not?
- Strength of trend
- Negative or positive

Try to use the words relationship and trend over correlation... i think.
UPDATE: we can use correlation, that is the point of linear regression 

the equation is 

y_hat = intercept(y maybe b0 in stats) + slope(m in math, b1 in stats(i think)) * x

im used to this
y = m*x + b 
stats is
y_hat = b0 + b1*x

df = n - 2 

test stat = (b1 - 0) / se of b1 (note that this is not sqrting n style)
Correlation is between -1, 1 with -1 being strong neg, 0 being no relationship and 
1 being strong pos relationship

CONDITIONS FOR LINEAR REGRESSION

- Linearity - The data should show a linear relationship 
- Nearly normal residuals - normalish distribution of residuals no crazy outliers 
- Constant variability - even spread of variance in residuals on either side of the zero line 
- Independence - duh

t_stat = slope - 0 / se (se is the standard error of the slope)

To compute the slope for a regression line we use the point slope... remember..?

y - y0 = slope * (x - x0)

so b0 is the intercept and b1 is the slope 

R is the correlation of the linear relationship and 
R**2 is used to describe the strength of the fit and how much the model accounts 
for the variance in the data.
So if r = 0.97 then R**2 = 0.94 and so 94% of variance in our data is explained 
by our model or 94% of the response is explained by the explantory variable

TYPE OF OUTLIERS  

Outliers that are far away from the rest of the data and far away from the regression line 
are called highly leveraged and are highly influential on the line 

Ho: slope = 0, Or there is no relationship between x and y
ha: slope != 0, There is a relationship between x and y 

t = slope - 0 / se

se should be the std err from the software 

CONFIDENCE INTERVAL 

Same as everything in the T testing 

point estimate +/- t_star(df) * se 
point estimate is b1 or the slope, and se is the std error from computer software 

_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+
CHI SQUARED GOODNESS OF FIT 

We take our test values and multiply them out by our expected to get what we 
would expect be the values for our distribution. i.e if we expect 40% x and 60% y 
and we have n=100 and 35 x and 75 y in our sample, we do 
x = 35
y = 65 

expected x = 100 * 0.4 = 40 
expected y = 100 * 0.6 = 60

ho: The proportions are randomly sampled there is no bias 
ha: The proportions arnt randomly sampled, there is a bias 

The test is called goodness of fit as we are evaluating how well the observed 
data fit the expected distribution 

df = k - 1 where k is groups

CONDITIONS 
–
- Independence 
- Sample size - each particular scenario must have at least n=5 expected cases
This means that if we expect 10% of our population to fall into a group and we 
have n = 25, then 0.1*25 would = 2.5 which is less than five, so we fail this condition 
even though in our sample there is more then 5 x, it doesnt matter, it is what 
is expected and not observed.
- df > 2 - atleast two groups (revision lecture she said atleast 3 gorups)


When presenting the finds use
Chisquared =- 2.32 on 2df and p-value = 0.31 

_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+
CHI SQUARED TEST OF INDEPENDENCE 

When looking for an asscottation between two categorical variables.

Same test as goodness of fit 

ho: a and b are independent, a does not vary by b, a and b are not assicated 
ha: a and b are dependent, a does vary with b a and b are associated 

df = (rows - 1) * (columns - 1) 

expected counts = (row total) * (column total) / table total 

Conditions
-independence 
- Sample size - all expected values are >=5 
- Two or more categories/groups in each variable 

If you have 3 or more sample sizes that arnt >=5, you can combined groups to get 
them over 5, but one or two groups < 5 is ok.


Example write up 

Since the pvalue of 0.856 (df=4, x = 1.31) is larger then 0.05, we do not reject the null
hypothesis and say that the data does not provide convincing evidence that class and 
choice are dependent.


All four short answer questions will have 
- Make a decision, and interpret it in context of the research question. - interpret conf int 
if it applies to the test. 

- P avlue decision, > < 0.05 
- reject or not rejecting 
answering research question, then anything extra 

extra 
t test - interpret conf int 
anova - look at pair wise t test 
lin reg - give equation and r**2 on variance 

Just say if we have enough evidence to support the null hypothesis or not. 

 -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=--=-=-=-=-=-=-
TYPES OF ERRORS

type 1 error - rejecting the null when Ho is true, finding someone guilty when 
they innocent
type 2 error - failing to reject the null when Ha is true, finding someone 
innocent when they are guilty.ˆ¨¥†®´∑œåß∂ƒ©˙∆˚¬…æ÷≥≤µ˜∫√ç≈Ω¡™£¢∞§¶•ªº–≠‘“«÷π









=-=-==-=-=-=-=-=-=-=-=-=-=-=--=j-j-=-j-=--=-=j-=-=-=---=-=--=---=-=-j=-j=-=-=-=

2019 Exam 

q1 - 4 
q2 - 5 
q3 - 1 
q4 - 5 

q5 - 4 
q6 - 3 

q7 - 5 
q8 - 1 

q9 - 3 was thinking 1 at first 
q10 - 1 

q11 - 1 
q12 - 2 

q13 - 2 
q14 - 5 

q15 - 2 
q16 - 4 

q17 - 3
q18 - 4 

q19 - 5 
q20 - 5 

q26 
a) A two sample t test should be used as we want to know the mean between the 
two groups. Also each group are independent of each other as in it is not the same
mouse being used for both light exposure settings. 

b) 
Ho: µ_darkness - µ_light = 0 - There is no difference of weight gain between mice 
with darkness during sleep and mice with light during sleep. 
Ha: µ_darkness - µ_light < 0 - There is an increase in weight gain for mice sleeping 
in light vs those sleeping in darkness. 

c) 
With test stat of t = -4.5385 and df = 10.939 with a p value of 0.0008579 which 
is < 0.05, we can say that our data provides enough evidence to reject the null 
hypothesis and say that there is a difference in weights between mice who sleep in 
darkness and those who sleep in light. More over we can conclude in saying that with 
a negaative t stat comparing darkness to light, we can say that mice sleeping in 
light tend to see an increase in weight. 

q27
a) This is an experiement as we are manipulating variables between two groups 
b) The response varible is the weight of the cow 
c) A cow may be pregnant during the experiment therefore leading to more weight gain 

q28 
a) We will be doing an ANOVA test of a difference of means between the three groups 
Ho: µ_site1 = µ_site2 = µ_site3 - There is no difference in weight between any of 
the groups
Ha: There is a difference in weights in atleast one group, we wont show this 
mathmatically as there are many variaous combinations

conditions 
Indenpence - Each frog is his own frog and a frog of his own, there fore we have
independence of frogs for our sites.... we also assume independence between groups 
as we arnt provided with any extra information about the frogs. One could actually 
argue that we dont have independence as from the explaination of the question, it 
sounds like we are taking a bunch of frogs from two areas and placing them in a 3rd 
area, then taking all the weight measurements from the new 3rd site and comparing 
to the old two sites? ie, those same frog measurements have been used for site 1 and 2 
before being moved? In that case, we dont have independence really, but for the sake 
of the exam.... it is assumed we have independence. In the real world I would enquire 
about this though. 

equal variance  - 1.59 / 1.19 < 2 therefore we have equal variance 

nearly normal disto - site 1 and 3 have similiar skew, but not egregious and there 
are no outliers in the data so this is fien to continue with. 

df = 3 gorups - 1 = 2 

assuming you dont want us to do all the math calcs?

with an F stat of 4.57 on df = 48 we have a pvalue = 0.015 < 0.05 which means we 
can reject the null hypothesis and say that our data shows that there is a significant 
difference in the wieghts of the frogs between the sites. With  site 3 having the 
largest mean weight we can conclude that the new habitat is indeed better, though 
now they are all chubby little boys ayyye 

se = 2.44/(14)**0.5

0.85 + 2.01 * se = 2.16
0.85 - 2.01 * se = 0.46 

With 95% confidence we say that frogs in site one 
I USED THE WRONG STATS BUT THE PROCESS WAS CORRECT. 

c) 
Becasue it is not mentioned we assume weeight is measured in grams for this conclusion 

with 95% confidence we can say that the average wegight gain for a frog in site 3 
is ATLEAST 1.05g - 2.21g MORE then a frog living in site 2 and the weight gain is 
again larger than this when comparing frogs from site 3 to site 1. Therefore we can 
conclude that is weight gain is the most important factor for a frogs life, then the 
moving of the froggies to site three was a success as they have become american... i mean 
gained weight and therefore live a better life? weight gain is a bad metric exam giver.


q29 
a) I drew it in my mind 
b) It is a strong negative linear relationship
c) 
Residuals are not even throughout the data, that is to say that there is not 
equal variance or the residuals across the distribution. 

d) 
i) y_hat = 6.77 + -0.044 * x(days)

ii) 5.7 = 6.77 + -0.044 * x 
    5.7 - 6.77 = -0.044 * x 
    -1.07 = -0.044 * x 
    -1.07 / -0.044 = x 
    24.31 = x 
    approximately 24 days is when you could expect the level to be at 5.7

iii) We can say with 95% confidence that each day that passes, the concentration 
of moxi in a meat of sheep decreases by (0.03 - 0.05)µg per kg 


q30 
a) 132 * 32 / 635 = 6.65 or 7 for whole humans 
b) (rows - 1) * (col - 1) 
= (5 - 1) * (3 - 1)
= 4 * 2 = 8 
df = 8 

c) with a X**2 value of 19.019 on 8 df and a p value = 0.01476 which is < 0.05 
we reject the null hypothesis that there is no relationship between dominate hand
and career and say that our data shows significant evidence there is a  
relationship between dominate hand and career 



-=-=--=-=-=-=-=-=-=-=-===-=--=-=-=--==--=-==-=-=-=-=-=-==-=-=-=-=-=-=-=-=-=-===
EXAM 1 of 3 
question, my answer, truth
q1 - 2, 2
q2 - 5, 1 

q3 - 1, 1
q4 - 2, 5
q5 - 4, 4 

q6 - 2, 3
q7 - 3, 3 

q8 - 5, 5 
q9 - 3, 3 
q10 - 2, 2 

q11 - 3, 3 
q12 - 4, 4 

q13 - 1, 1
q14 - 5, 1(this is wrong though, it is 5)

q15 - 4, 4 

q16 - 1, 1 
q17 - 2, 2 

q18 - 1, 1 
q19 - 3, 2 

q20 - 3, 3 

q21 - 2, 2 
q22 - 1, 1 

q23 - 3 3 
q24 - 3 1 
q25 - 1 1 

q26 
a) weak negative linear relationship, there is an outlier in the center of the 
center of the data, but it is not effecting the relationship.

Solution: From the above plot, it appears that there is a weak negative linear
relationship between Nitrogen Dioxide levels and Air Temperature. That is,
as Air Temp increases, Notrigen Dixoide decreases. There is weak correlation
between the variables, with a lot of variability about the trend line.

b) it is clearly not a perfectly straight 45 degree line from top to bottom. 
That being I still think it is resonable as all but one of the data points are 
in a uniform line that isnt deviating too far from the center diagonal. 

Solution: The QQ plot appears relatively linear, suggesting that the assumption
of Normality is reasonable. There is one noticeable outlier (at the lower tail)
which could be investigated.

c) nitro_dioxide_hat = 125.67 - 0.46 * air_tewmpreature 

d) 111.87units 

e) 
-0.4647 + 2.02 * 0.2189 = -0.023
-0.4647 - 2.02 * 0.2189 = -0.906

f) With 95% confidence we say that for every degree increase in air temp the 
nitoxi level decreases by (0.023 to 0.906) units (units were not given)


q27
a) explanatory variable: rainfall conditions 
response variable: farmers mental state 
sample: 664 farmers of both genders from age 55 to 64 
population: all farmers who either work or live on a farm 

Solution:
Explanatory variable: Climatic conditions (i.e., both drought and wet conditions)
Response variable: Farmers’ mental health
Sample: 664 farmers from inner and outer regional, remote, and very remote New
South Wales (NSW).
Target population: Both male and female farmers from NSW between the ages of
55 - 64 years old.

b) Yes and this would be due to them being farmers... their life, work, wealth,
way of life, living standards... literally everything hinges on them being able 
to farm the land. Its not secret that droughts kill crops, live stock and the 
land itself.... therefore this seems like generally correct relationship and 
logical step to take. 

Solution:
This study was an observational study not a randomized experiment so we cannot
assert that there is a cause-and-effect relationship here, only a correlation. 
Furthermore, there may be many confounding variables that also need to be 
considered in the context of this study.


q28 
a) N(1272, 35)


b) (1307 - 1272) / 35 = 1 


c) t(df=15, µ=1272, std=35)

Solution: Let /barX represent the mean tree ring date for samples of size 16.
Then,
X¯ ∼ N(µ, σ/√
n) = N(1272, 35/4) = N(1272, 8.75).

d) (1307 - 1272) / 35/16**0.5 = 4

e) We were using a normal distribution for the question in b, which means we 
just simple minus the mean from the sample and divide the by standard deviation 

but in d we are looking at a value from a sample of 16 

Solution: We know that individual values are more variable than means. The
standard deviation for the sampling distribution (σ/√n) is much smaller (by a
factor of 4) than the standard deviation of the population. Hence, in terms of
std deviations (which is what the z-score measures) a value of 1307 will lie much
further away from the mean of the sampling distribution than a single observation
of 1307 will lie away from the population mean.The figure below shows the two
distributions (N(1272, 35) and N(1272, 8.75)) superimposed.

f) Yes, the object at site A was one std outside of the mean therefore we can 
say that roughly is falls within 32% of trees in the site, where as the site b 
is 2,5 std and so is somewhere in the 4 - 5% of trees.

Solution: The item from Site B, with a z-score of 2.75, is the more unusual of
the two items. The 68-95-99.7 Rule states that approximately 95% of the normal
distribution will fall within 2 sd of the mean. Hence, the item from Site B is falling
in the upper 2.5% of all ring-dated items at that site. The year recorded for the
object from Site A is only 1 sd above the mean, and so at least 16% of all items
at Site A would record an age greater than 1307.


q29 
a) Ho: µ_camp1 = µ_camp2 - There is no difference in mean days spent between 
the two camps 

b) two sample t test 

c) :
independence 
nearly normal distribution 


d) t = -7.836, df = 186.2, pvalue = 0.000 

e) From the values above we reject the null hypothesis and say that there is a 
significant difference in days spent between the two camps. Furthermore we can 
say that on average flying foxes spent between 10 - 17 days more at tamworth 
then armidale. 

f) weather, perhaps the foxes were tamworth for the winter and it was a particularly 
cold winter or lasted a little longer so they didnt leave until it warmed up. 


=-=-=-=-=-=-==-=-=-=-=-=-=-==--=--==-==-==-=-=-=-=-=-=-==-=-=-=-=-=-==-=-==-=-=-
Exam 2 electric booo ga loo 

q1 - 3 
q2 - 2 
q3 - 3 
q4 - 3, 5 - Study mutually exclusive probabilities , cheet sheet it maybe 

q5 - 3 
q6 - 3 

q7 - 5 
q8 - 5 

q9 - 2 
q10 - 5 

q11 - 5 
q12 - 3 

q13 - 3, 2 study sampliong distrtubtion definitions 
q14 - 5 

q15 - 2 
q16 - 2 

q17 - 1 
q18 - 5 
q19 - 3  
q20 - 4 

q21 - 3 
q22 - 3 
q23 - 1 

q24 - 4 
q25 - 3 

q26 
a) N(df=8, µ=10, std=1.5) WRONG just do the std sum and show N(10, 0.5) no dfs 


b) 10 +- 1.96 * (1.5 / 9**0.5)
= (9.02 - 10.98)

My reasoning is to take the mean of 10, calculate the standard error blah blah
actually this could be a trick question and you want 10 +- 2.01 * 1.5/9**0.5 
= (8.995 - 11.005)

Second one was more correct, we did need to use the tstar once with the 95% 
manipulated to dfs 

c) 
i) (8.5 - 10) / (1.5/9**0.5 = -3 
ii) the answer is - 3 stds which would put it at less then 1% chance, 0.5% chance 
to be exact that they would observe... due to thumb rule

d) (8.5 - 10) / 1.5/25**0.5 = -5 
very unlikely, being 5stds away from the center of the data would put it far smaller
of a chance then 0.5% 

q27 
a) riding position 

WRONG it was riding pos, direction and speed 

b) They didn't introduce randomiszation, it sounds like they put out an add for 
cyclists to be part of a study. Now 200 were used, did they get exactly 200 
responses? maybe not, so they may have added randomness by selecting at random 
only 200 of the total number of volunteers. 

HALF RIGHT, Order of treatments should have been understaken in random order 
for each participant. 

c) No, this was an observational study and not an experiment, you would need to 
undergo a far more intense experiemtnal study to derive any trustworthy results.

GIGAWRONG - Only vlunteers, only 10km per week, only men, many factors unaccounted 
for, like fatigue from previous days activity, type of bike, plus the other stuff 
i said.

q28 
a) 
Ho: µ_1 = µ_2 = µ_3... etc - There is no difference in gnome size between the 
families.
Ha: There is atleast one family with a genome size that differs from the others. 
No notation due to lots of combinations 

b)
Independence has been met 
equal variance has been met with the smallest std times 2 is still less then the 
largest std. 
Nearly normal data - This has argueably not been met, there is large skew and 
outliers in two of the groups. group 1, 3, 4 are fine even though 1 has some skew,
it is fine. But groups 2 and 5 both have large skew and large outliers, therefore 
nearly normal has not been met 


c) 
i) df = 4 
mean sq = 24.551 

ii) with a p value of 0.0001 which is far smaller then 0.05, we reject the null 
hypothesis and say that there is significant evidence that atleast one groups 
genome size is different than the others

d) 
With 95% confidence we can say that Branchiopods have the smallest genomes out 
of all the familys with an average size of (-0.2 - 1.9) smaller on average and 
the isopods have the largest genome size with an average of (3.76 - 6.24)units 
bigger then the others on average. Though the ostreacosd have a smaller genome 
to the downside, they have a larger onme to the upside then the branchiopods. 
The barcnacles and copepods are sitting somewhere in the middle with intervals 
or blah and blah 

IKINDA WRONG OR ATLEAST NOT CONCISE.
State that with 95% confidence we think that mean genome is contained. Talk 
about how the largest sees no overlap to the others and therefore on avgerae is 
the largest, then talk about the overlap of the others, the olowest if poissible 
otherwise state we cannot tell if there is any different because they overlap.

q29

a)  We seems that we have a positive strong linear relationsihp. 

b) The qqplot looks ok, there is a little bit of downwards curre towards the bottom 
but overall the residual line is fairly straight with no egregious breaches, I 
would say that this is fine to continue with. 

c) cirps_hat = 6.48115 + 0.38117*air_temp 

d) cirps = 6.48115 + 0.38117*31 
= 18.3 
logically rounding down to 18 

e)
Ho: r = 0 - There is no relationshi[ bnetween temp and amount of cricket cirps 
Ha: r!= 0 - There is a relationship between temp and amount of cricket cirps 

intercept (b_o) = 6.48, slope (b_1) = 0.38, t-value = 5.5 

With a pvalue of 0.004 whih is less than 0.05 we have enough evidence to reject the 
nu,ll hyp[othesis and say there is a realationship between temp and cirp number.

We can sday that 70% of variance in our cirp data is explained by the tempreature.

for every degree in temperatiure rise, we can expect 0.38 more cricket cirps on 
    average. 

